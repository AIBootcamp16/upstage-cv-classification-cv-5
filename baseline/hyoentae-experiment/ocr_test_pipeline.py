# -*- coding: utf-8 -*-
# filename: ocr_test_pipeline.py
"""
íë¦¼ + íšŒì „ + ì¢Œìš°ë°˜ì „ì´ ì„ì¸ test ë°ì´í„°ì—ì„œ OCR ë¦¬ì½œì„ ëŒì–´ì˜¬ë¦¬ëŠ” 'ë¹ ë¥¸' ë©€í‹°íŒ¨ìŠ¤ íŒŒì´í”„ë¼ì¸ (ìµœì†Œ ì¦ê°•).

ë³€ê²½ ìš”ì•½ (ì†ë„ ìµœì í™”)
- ìŠ¤ì¼€ì¼ ì—…(1.5/2.0), CLAHE+Unsharp, Bilateral, Adaptive ì œê±°
- ì „ì²´ íŒ¨ìŠ¤: (0Â°, 180Â°) Ã— (ì›ë³¸, ì¢Œìš°ë°˜ì „) = 4íšŒë§Œ
- í•„ìš” ì‹œì—ë§Œ Otsu ì´ì§„í™” 1íšŒ ì¶”ê°€ ì‹œë„
- ìƒë‹¨ íƒ€ì´í‹€ í¬ë¡­ 1íšŒë§Œ (ratio=0.22), ìœ„ì™€ ë™ì¼í•œ ìµœì†Œ íŒ¨ìŠ¤
- ì´ˆëŒ€í˜• ì´ë¯¸ì§€ëŠ” max_side ê¸°ì¤€ í•œ ë²ˆë§Œ ë‹¤ìš´ìŠ¤ì¼€ì¼

ì‚¬ìš© ì˜ˆì‹œ
python test_subclass.py \
  --img_dir datasets_fin/test \
  --out_csv datasets_fin/test_ocr.csv \
  --make_parent_scores \
  --make_subclass \
  --keep_ext
"""

import sys
from pathlib import Path
import argparse
import unicodedata

import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm

# ì™¸ë¶€
try:
    import easyocr
    import regex as cregex
    from rapidfuzz import fuzz
except Exception as e:
    print("âŒ í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜:", e)
    print("pip install easyocr opencv-python numpy pandas regex rapidfuzz tqdm")
    sys.exit(1)

# =========================
# OCR ì´ˆê¸°í™”
# =========================
def init_reader():
    try:
        # paragraph=Falseê°€ ì¡°ê¸ˆ ë” ë¹ ë¥¸ í¸
        rdr = easyocr.Reader(['ko', 'en'], gpu=True)
        print("âœ… EasyOCR ì´ˆê¸°í™” (GPU=True)")
        return rdr
    except Exception as e:
        print(f"âš ï¸ GPU ëª¨ë“œ ì‹¤íŒ¨: {e}\n   GPU=Falseë¡œ ì¬ì‹œë„í•©ë‹ˆë‹¤.")
        rdr = easyocr.Reader(['ko', 'en'], gpu=False)
        print("âœ… EasyOCR ì´ˆê¸°í™” (GPU=False)")
        return rdr

reader = init_reader()

# =========================
# í…ìŠ¤íŠ¸ ì •ê·œí™” ìœ í‹¸
# =========================
def normalize_text(text: str) -> str:
    t = unicodedata.normalize("NFKC", text or "")
    t = t.lower()
    t = cregex.sub(r"[\p{Cc}\p{Cf}]", " ", t)              # ì œì–´ë¬¸ì ì œê±°
    t = cregex.sub(r"[^\p{Hangul}\p{Latin}\p{Nd}\s\.\-_/Â·:;]", " ", t)  # í—ˆìš©ë¬¸ìë§Œ
    t = cregex.sub(r"\s+", " ", t).strip()
    return t

def nospace(s: str) -> str:
    return cregex.sub(r"[\s\.\-_/Â·:;]+", "", s or "")

# =========================
# (ì°¸ê³ ) ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤ - í˜„ì¬ ë¹ ë¥¸ íŒŒì´í”„ë¼ì¸ì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
# =========================
def enhance_clahe_unsharp(img):
    """ëŒ€ë¹„ í–¥ìƒ + ìƒ¤í”„ë‹ (ë¯¸ì‚¬ìš©: ì†ë„ ìµœì í™”ë¡œ ì œì™¸)"""
    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l,a,b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=1.8, tileGridSize=(8,8))
    cl = clahe.apply(l)
    lab = cv2.merge((cl,a,b))
    y = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
    bl = cv2.GaussianBlur(y,(0,0),1.0)
    sharp = cv2.addWeighted(y, 1.25, bl, -0.25, 0)
    return sharp

def to_otsu(img):
    """Otsu ì´ì§„í™” (í•„ìš”í•œ ê²½ìš°ì—ë§Œ 1íšŒ ì ìš©)"""
    g = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    th = cv2.threshold(g, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY)[1]
    return cv2.cvtColor(th, cv2.COLOR_GRAY2BGR)

def to_adaptive(img):
    """ë¯¸ì‚¬ìš©: ì†ë„ ìµœì í™”ë¡œ ì œì™¸"""
    g = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    th = cv2.adaptiveThreshold(g, 255,
                               cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                               cv2.THRESH_BINARY, 31, 10)
    return cv2.cvtColor(th, cv2.COLOR_GRAY2BGR)

def bilateral(img):
    """ë¯¸ì‚¬ìš©: ì†ë„ ìµœì í™”ë¡œ ì œì™¸"""
    return cv2.bilateralFilter(img, d=7, sigmaColor=50, sigmaSpace=50)

# =========================
# ë©€í‹°íŒ¨ìŠ¤ OCR (ë¹ ë¥¸ ë²„ì „)
# =========================
TITLE_RATIOS = [0.22]     # ìƒë‹¨ íƒ€ì´í‹€ í¬ë¡­ ë¹„ìœ¨ (1íšŒë§Œ)
ROTATIONS    = [0, 180]   # íšŒì „
FLIPS        = [0, 1]     # 0: none, 1: ì¢Œìš°ë°˜ì „

def crop_title(img, ratio):
    H, W = img.shape[:2]
    h = max(10, int(H * ratio))
    return img[:h, :]

def rotate_image(img, deg):
    if deg == 0:
        return img
    h, w = img.shape[:2]
    M = cv2.getRotationMatrix2D((w//2, h//2), deg, 1.0)
    return cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)

def _resize_cap(img, max_side=1600):
    """ì´ë¯¸ì§€ê°€ ë„ˆë¬´ í° ê²½ìš°ë§Œ ë‹¤ìš´ìŠ¤ì¼€ì¼ (ì—°ì‚°ëŸ‰ ì ˆê°)"""
    h, w = img.shape[:2]
    m = max(h, w)
    if m <= max_side:
        return img
    r = max_side / float(m)
    return cv2.resize(img, (int(w*r), int(h*r)), interpolation=cv2.INTER_AREA)

def _try_ocr_once(img) -> str:
    """ì›ë³¸(ë˜ëŠ” ë³€í˜•ë³¸)ì— í•œ ë²ˆ ì½ê¸°"""
    try:
        res = reader.readtext(img, detail=0, paragraph=False)
        return normalize_text(" ".join(res))
    except Exception:
        return ""

def _try_ocr_otsu(img) -> str:
    """Otsu í•œ ë²ˆë§Œ (í•„ìš”í•  ë•Œë§Œ)"""
    try:
        g  = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        th = cv2.threshold(g, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY)[1]
        th3 = cv2.cvtColor(th, cv2.COLOR_GRAY2BGR)
        res = reader.readtext(th3, detail=0, paragraph=False)
        return normalize_text(" ".join(res))
    except Exception:
        return ""

EARLY_KWS = [
    "ì…ì›í™•ì¸","ì…í‡´ì›","ì…ì›ì‚¬ì‹¤","ì…ì›ì¦ëª…","ì…ì› ìš”ì•½","ì…ì›ìš”ì•½",
    "í†µì›í™•ì¸","í†µì›ì§„ë£Œ","ì™¸ë˜ì§„ë£Œ","ì§„ë£Œì‚¬ì‹¤","ì¹˜ë£Œí™•ì¸","í†µì›ì¹˜ë£Œì‚¬ì‹¤",
    "ì†Œê²¬ì„œ","ì§„ë£Œì†Œê²¬","ì˜ì‚¬ì†Œê²¬","ì§„ë‹¨ì†Œê²¬"
]

def extract_text_multi(img_path: Path) -> str:
    img = cv2.imread(str(img_path))
    if img is None:
        return ""
    img = _resize_cap(img)  # ê³¼ëŒ€í•´ìƒë„ë§Œ ë‹¤ìš´ìŠ¤ì¼€ì¼

    texts = []

    # 1) ì „ì²´ ì´ë¯¸ì§€: ìµœì†Œ íŒ¨ìŠ¤ (ì›ë³¸ â†’ 180Â°) Ã— (ì¢Œìš°ë°˜ì „ Off/On)
    for rot in ROTATIONS:
        rotated = img if rot == 0 else rotate_image(img, rot)
        for flip in FLIPS:
            base = rotated if flip == 0 else cv2.flip(rotated, 1)

            # (a) ì›ë³¸ í•œ ë²ˆ
            t = _try_ocr_once(base)
            if t:
                texts.append(t)
                if any(kw in t for kw in EARLY_KWS):
                    return t

    # 2) ì „ì²´ ì´ë¯¸ì§€: ì•ˆ ì¡íˆë©´ Otsu í•œ ë²ˆë§Œ ì „ì²´ì— ì‹œë„
    for rot in ROTATIONS:
        rotated = img if rot == 0 else rotate_image(img, rot)
        for flip in FLIPS:
            base = rotated if flip == 0 else cv2.flip(rotated, 1)

            t = _try_ocr_otsu(base)
            if t:
                texts.append(t)
                if any(kw in t for kw in EARLY_KWS):
                    return t

    # 3) ìƒë‹¨ íƒ€ì´í‹€ í¬ë¡­: 1íšŒë§Œ (ì›ë³¸ â†’ 180Â°) Ã— (ì¢Œìš°ë°˜ì „ Off/On)
    for ratio in TITLE_RATIOS:
        top = crop_title(img, ratio)

        # (a) ì›ë³¸ í•œ ë²ˆ
        for rot in ROTATIONS:
            rotated = top if rot == 0 else rotate_image(top, rot)
            for flip in FLIPS:
                base = rotated if flip == 0 else cv2.flip(rotated, 1)

                t = _try_ocr_once(base)
                if t:
                    texts.append(t)
                    if any(kw in t for kw in EARLY_KWS):
                        return t

        # (b) í•„ìš”ì‹œì—ë§Œ Otsu í•œ ë²ˆ
        for rot in ROTATIONS:
            rotated = top if rot == 0 else rotate_image(top, rot)
            for flip in FLIPS:
                base = rotated if flip == 0 else cv2.flip(rotated, 1)

                t = _try_ocr_otsu(base)
                if t:
                    texts.append(t)
                    if any(kw in t for kw in EARLY_KWS):
                        return t

    # í…ìŠ¤íŠ¸ ì¤‘ë³µ ì œê±° í›„ í•©ì¹˜ê¸°
    uniq, seen = [], set()
    for t in texts:
        k = nospace(t)
        if k and k not in seen:
            seen.add(k)
            uniq.append(t)
    return normalize_text(" ".join(uniq))

# =========================
# (ì˜µì…˜) 3/7/14 ë¶€ëª¨Â·ì„œë¸Œí´ë˜ìŠ¤ ë§¤í•‘
# =========================
# OCR í”ì˜¤íƒˆ ì¹˜í™˜ì€ ì •ê·œí™”ì™€ í¼ì§€ë¡œ í¡ìˆ˜í•˜ë¯€ë¡œ ë‹¨ì–´ ì›í˜•ë§Œ ìœ ì§€
CLASS_KEYWORDS = {
    3: { 0: ['ì…í‡´ì›ì‚¬ì‹¤í™•ì¸ì„œ', 'ì…í‡´ì›í™•ì¸ì„œ', 'ì…ì›í™•ì¸ì„œ'],
         1: ['ì…ì›ì‚¬ì‹¤ì¦ëª…ì„œ', 'ì…ì›ì‚¬ì‹¤ì¦ëª…ì›', 'ì…í‡´ì›ì‚¬ì‹¤ì¦ëª…ì„œ'],
         2: ['ì…ì›ì¦ëª…ì„œ', 'ì…ì›í‡´ì›ì¦ëª…ì„œ'],
         3: ['ì…ì›ì§„ë£Œí™•ì¸ì„œ', 'ì…ì› ì§„ë£Œí™•ì¸ì„œ'],
         4: ['ì…ì›ìš”ì•½ì§€', 'ì…ì› ìš”ì•½ì§€'] },
    7: { 0: ['í†µì›í™•ì¸ì„œ', 'í†µì›ì§„ë£Œí™•ì¸ì„œ'],
         1: ['ì§„ë£Œí™•ì¸ì„œ', 'ì§„ë£Œì‚¬ì‹¤í™•ì¸ì„œ'],
         2: ['ì™¸ë˜ì§„ë£Œì‚¬ì‹¤í™•ì¸ì„œ', 'ì¹˜ë£Œí™•ì¸ì„œ'],
         3: ['í†µì›ì¹˜ë£Œì‚¬ì‹¤í™•ì¸ì„œ', 'ì§„ë£Œì‚¬ì‹¤ì¦ëª…ì„œ'],
         4: ['ì™¸ë˜ì§„ë£Œí™•ì¸ì„œ', 'ì™¸ë˜ ì§„ë£Œ í™•ì¸ì„œ'],
         5: ['ì¹˜ë£Œì‚¬ì‹¤í™•ì¸ì„œ', 'ì¹˜ë£Œ ì‚¬ì‹¤ í™•ì¸ì„œ'] },
    14:{ 0: ['ì†Œê²¬ì„œ', 'ì§„ë£Œì†Œê²¬ì„œ', 'ì˜ì‚¬ì†Œê²¬ì„œ', 'ì§„ë‹¨ì†Œê²¬ì„œ', 'ì„ìƒì†Œê²¬ì„œ'] }
}

PARENT_RULES = {
    3: {"title": ["ì…ì›í™•ì¸ì„œ", "ì…ì›ì‚¬ì‹¤", "ì…í‡´ì›", "ì…ì›ì¦ëª…", "ì…ì› ì§„ë£Œí™•ì¸", "ì…ì› ìš”ì•½"],
        "pos":   ["ì…ì›", "í‡´ì›", "ì…í‡´ì›", "ìš”ì•½ì§€", "ì§„ë£Œìš”ì•½"],
        "neg":   ["í†µì›", "ì™¸ë˜"]},
    7: {"title": ["í†µì›í™•ì¸ì„œ", "ì§„ë£Œí™•ì¸ì„œ", "í†µì›ì§„ë£Œ", "ì™¸ë˜ì§„ë£Œì‚¬ì‹¤", "ì¹˜ë£Œí™•ì¸", "ì§„ë£Œì‚¬ì‹¤", "í†µì›ì¹˜ë£Œì‚¬ì‹¤",
                  "ì™¸ë˜ì§„ë£Œí™•ì¸", "ì¹˜ë£Œì‚¬ì‹¤í™•ì¸"],
        "pos":   ["í†µì›", "ì™¸ë˜", "ì§„ë£Œì‚¬ì‹¤", "ì¹˜ë£Œì‚¬ì‹¤", "ì¹˜ë£Œí™•ì¸", "ë‚´ì›", "ì™¸ë˜ì§„ë£Œ", "í†µì›ì¹˜ë£Œ"],
        "neg":   ["ì…ì›", "í‡´ì›", "ì…í‡´ì›", "ì…ì›ì§„ë£Œ", "ì…ì›ìš”ì•½"]},
    14:{"title": ["ì†Œê²¬ì„œ", "ì§„ë£Œì†Œê²¬ì„œ", "ì˜ì‚¬ì†Œê²¬ì„œ", "ì§„ë‹¨ì†Œê²¬ì„œ"],
        "pos":   ["ì†Œê²¬"],
        "neg":   ["ì§„ë‹¨ì„œ", "í™•ì¸ì„œ", "ì§„ë£Œí™•ì¸", "ì‚¬ì‹¤í™•ì¸"]}
}

def contains_keyword(text: str, keyword: str, fuzzy_threshold: int = 82) -> bool:
    t = normalize_text(text)
    # ê°„ê²©/ì  í—ˆìš© ì •ê·œì‹
    gap = r"[\s\.\-_/Â·:;]*"
    pat = gap.join([cregex.escape(ch) for ch in keyword])
    rx = cregex.compile(pat, cregex.IGNORECASE)
    if rx.search(t):
        return True
    if nospace(keyword) in nospace(t):
        return True
    return fuzz.partial_ratio(keyword, t) >= fuzzy_threshold

def score_parent_class(text: str, class_id: int, fuzzy_threshold: int = 82) -> int:
    rules = PARENT_RULES[class_id]
    s = 0
    for kw in rules["title"]:
        if contains_keyword(text, kw, fuzzy_threshold): s += 3
    for kw in rules["pos"]:
        if contains_keyword(text, kw, fuzzy_threshold): s += 1
    for kw in rules["neg"]:
        if contains_keyword(text, kw, fuzzy_threshold): s -= 3
    return s

def match_subclass_specific(class_id: int, text: str, fuzzy_threshold: int = 82) -> int | None:
    if class_id not in CLASS_KEYWORDS:
        return None
    for sub_id, kws in CLASS_KEYWORDS[class_id].items():
        for kw in kws:
            if contains_keyword(text, kw, fuzzy_threshold):
                return sub_id
    return None

DEFAULT_SUBCLASS = {3: 9, 7: 9, 14: 9}  # OTHERë¡œ í´ë°±

def decide_parent_and_subclass(text: str, fuzzy_threshold: int = 82, parent_tau: int = 1):
    scores = {c: score_parent_class(text, c, fuzzy_threshold) for c in (3,7,14)}
    best_parent = max(scores, key=scores.get)
    best = scores[best_parent]
    second = sorted(scores.values(), reverse=True)[1]
    if best >= parent_tau and best >= second + 1:
        sub_id = match_subclass_specific(best_parent, text, fuzzy_threshold)
        if sub_id is None:
            sub_id = DEFAULT_SUBCLASS[best_parent]
        return best_parent, sub_id, scores, best-second
    return None, None, scores, 0

# =========================
# ë©”ì¸ ì‹¤í–‰
# =========================
def run(
    img_dir: str,
    out_csv: str,
    keep_ext: bool = True,
    make_parent_scores: bool = False,
    make_subclass: bool = False,
    fuzzy_threshold: int = 82,
    parent_tau: int = 1
):
    img_dir = Path(img_dir)
    paths = sorted([p for p in img_dir.glob("*") if p.suffix.lower() in {".png",".jpg",".jpeg",".tif",".tiff",".bmp",".webp"}])
    print(f"ğŸ“‚ Images: {len(paths)}ê°œ")

    rows = []
    for p in tqdm(paths):
        img_id = p.name if keep_ext else p.stem
        text = extract_text_multi(p)

        row = {"ID": img_id, "ocr_text": text}

        if make_parent_scores:
            s3 = score_parent_class(text, 3, fuzzy_threshold)
            s7 = score_parent_class(text, 7, fuzzy_threshold)
            s14 = score_parent_class(text, 14, fuzzy_threshold)
            scores = {3:s3, 7:s7, 14:s14}
            best_parent = max(scores, key=scores.get)
            best = scores[best_parent]
            second = sorted(scores.values(), reverse=True)[1]
            row.update({
                "parent_3": s3, "parent_7": s7, "parent_14": s14,
                "parent_best": best_parent if best >= parent_tau and best >= second + 1 else None,
                "parent_margin": best - second
            })

        if make_subclass:
            parent, sub, scores, margin = decide_parent_and_subclass(text, fuzzy_threshold, parent_tau)
            subclass_code = parent*10 + sub if (parent is not None and sub is not None) else None
            row.update({
                "target": subclass_code  # ì„œë¸Œí´ë˜ìŠ¤ ì½”ë“œ(31/71/141...) ë˜ëŠ” None
            })

        rows.append(row)

    df = pd.DataFrame(rows)

    # ì„œë¸Œí´ë˜ìŠ¤ ëª¨ë“œ: IDì™€ targetë§Œ ì¶œë ¥, targetì€ ì •ìˆ˜ë¡œ ë³€í™˜
    if make_subclass:
        df_out = df[["ID", "target"]].copy()
        # NaNì„ ìœ ì§€í•˜ë©´ì„œ ì •ìˆ˜ë¡œ ë³€í™˜ (Int64ëŠ” nullable integer)
        df_out["target"] = df_out["target"].astype("Int64")
    else:
        df_out = df

    Path(out_csv).parent.mkdir(parents=True, exist_ok=True)
    df_out.to_csv(out_csv, index=False)
    print(f"âœ… ì €ì¥ ì™„ë£Œ: {out_csv}")

if __name__ == "__main__":
    ap = argparse.ArgumentParser(description="ë©€í‹°íŒ¨ìŠ¤ OCR íŒŒì´í”„ë¼ì¸ (íë¦¼/íšŒì „/ì¢Œìš°ë°˜ì „ ëŒ€ì‘, ë¹ ë¥¸ ë²„ì „)")
    ap.add_argument("--img_dir", required=True, help="ì´ë¯¸ì§€ í´ë” (ì˜ˆ: datasets_fin/test)")
    ap.add_argument("--out_csv", required=True, help="ì €ì¥ ê²½ë¡œ (ì˜ˆ: datasets_fin/test_ocr.csv)")
    ap.add_argument("--keep_ext", action="store_true", help="IDì— í™•ì¥ì í¬í•¨ (SOTAì™€ ë™ì¼ í˜•ì‹ì´ë©´ ê¶Œì¥)")
    ap.add_argument("--make_parent_scores", action="store_true", help="3/7/14 ë¶€ëª¨ ì ìˆ˜/ë§ˆì§„ ì €ì¥")
    ap.add_argument("--make_subclass", action="store_true", help="ì„œë¸Œí´ë˜ìŠ¤ ì½”ë“œ(target=31/71/141...) ì €ì¥")
    ap.add_argument("--fuzzy_threshold", type=int, default=82, help="í‚¤ì›Œë“œ í¼ì§€ ì„ê³„")
    ap.add_argument("--parent_tau", type=int, default=1, help="ë¶€ëª¨ ì„ íƒ ì„ê³„")
    args = ap.parse_args()

    run(
        img_dir=args.img_dir,
        out_csv=args.out_csv,
        keep_ext=args.keep_ext,
        make_parent_scores=args.make_parent_scores,
        make_subclass=args.make_subclass,
        fuzzy_threshold=args.fuzzy_threshold,
        parent_tau=args.parent_tau
    )
