"""
Inference Script

TTA (Test Time Augmentation)ë¥¼ ì‚¬ìš©í•œ ì¶”ë¡  ë° submission.csv ìƒì„±

ì‚¬ìš©ë²•:
    # ê¸°ë³¸ ì¶”ë¡  (TTA ì‚¬ìš©)
    python inference.py checkpoint=outputs/2025-11-02/12-00-00/best.pth

    # TTA ì—†ì´ ì¶”ë¡ 
    python inference.py checkpoint=outputs/2025-11-02/12-00-00/best.pth use_tta=false

    # Config ì˜¤ë²„ë¼ì´ë“œ
    python inference.py checkpoint=best.pth model=efficientnet_b0
"""

import hydra
from omegaconf import DictConfig, OmegaConf
import torch
import pandas as pd
import numpy as np
from pathlib import Path
from tqdm import tqdm
import cv2

from src.models.classifier import create_model_from_config
from src.data.dataset import create_test_dataset, create_test_dataloader
from src.data.transforms import create_transforms_from_config, get_tta_transforms
from src.utils.checkpoint import load_model_for_inference, find_latest_checkpoint


@torch.no_grad()
def predict_with_tta(
    model: torch.nn.Module,
    image: torch.Tensor,
    tta_transforms: list,
    device: str
) -> np.ndarray:
    """
    TTA (Test Time Augmentation)ë¡œ ì˜ˆì¸¡

    ì—¬ëŸ¬ augmentationì„ ì ìš©í•œ ì´ë¯¸ì§€ë“¤ì˜ ì˜ˆì¸¡ì„ í‰ê· ëƒ…ë‹ˆë‹¤.

    Args:
        model: PyTorch ëª¨ë¸
        image: ì›ë³¸ ì´ë¯¸ì§€ (NumPy ë°°ì—´, RGB)
        tta_transforms: TTA ë³€í™˜ ë¦¬ìŠ¤íŠ¸
        device: ë””ë°”ì´ìŠ¤

    Returns:
        í‰ê·  ì˜ˆì¸¡ í™•ë¥  (shape: [num_classes])
    """
    predictions = []

    for transform in tta_transforms:
        # Augmentation ì ìš©
        augmented = transform(image=image)
        img_tensor = augmented['image'].unsqueeze(0).to(device)  # [1, C, H, W]

        # ì˜ˆì¸¡
        output = model(img_tensor)
        prob = torch.softmax(output, dim=1).cpu().numpy()[0]  # [num_classes]
        predictions.append(prob)

    # í‰ê·  í™•ë¥ 
    avg_prob = np.mean(predictions, axis=0)

    return avg_prob


@torch.no_grad()
def inference_with_dataloader(
    model: torch.nn.Module,
    test_loader,
    device: str,
    use_tta: bool = False,
    tta_transforms: list = None,
    test_img_dir: str = None,
) -> tuple:
    """
    DataLoaderë¥¼ ì‚¬ìš©í•œ ë°°ì¹˜ ì¶”ë¡ 

    Args:
        model: PyTorch ëª¨ë¸
        test_loader: Test DataLoader
        device: ë””ë°”ì´ìŠ¤
        use_tta: TTA ì‚¬ìš© ì—¬ë¶€
        tta_transforms: TTA ë³€í™˜ ë¦¬ìŠ¤íŠ¸ (TTA ì‚¬ìš© ì‹œ í•„ìš”)
        test_img_dir: Test ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ (TTA ì‚¬ìš© ì‹œ í•„ìš”)

    Returns:
        (img_ids, predictions) íŠœí”Œ
    """
    model.eval()

    all_img_ids = []
    all_predictions = []

    if use_tta:
        print("ğŸ”„ TTA (Test Time Augmentation) ì‚¬ìš©")
        print(f"   TTA ë²„ì „ ìˆ˜: {len(tta_transforms)}")

        # TTAëŠ” DataLoader ì‚¬ìš© ì•ˆ í•˜ê³  ê°œë³„ ì´ë¯¸ì§€ ì²˜ë¦¬
        test_img_dir = Path(test_img_dir)

        # sample_submission.csvì—ì„œ ì´ë¯¸ì§€ ID ì½ê¸°
        for images, img_ids in tqdm(test_loader, desc="Inference (TTA)"):
            for i, img_id in enumerate(img_ids):
                # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ê²°ì •
                # IDì— ì´ë¯¸ í™•ì¥ìê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                if img_id.endswith('.jpg') or img_id.endswith('.png'):
                    # IDì— ì´ë¯¸ í™•ì¥ì í¬í•¨ë¨
                    img_path = test_img_dir / img_id
                else:
                    # í™•ì¥ì ì—†ìŒ, jpg ë˜ëŠ” png ì‹œë„
                    img_path_jpg = test_img_dir / f"{img_id}.jpg"
                    img_path_png = test_img_dir / f"{img_id}.png"

                    if img_path_jpg.exists():
                        img_path = img_path_jpg
                    elif img_path_png.exists():
                        img_path = img_path_png
                    else:
                        print(f"âš ï¸  ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_id}")
                        continue

                # íŒŒì¼ ì¡´ì¬ í™•ì¸
                if not img_path.exists():
                    print(f"âš ï¸  ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_path}")
                    continue

                # ì´ë¯¸ì§€ ì½ê¸°
                image = cv2.imread(str(img_path))
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

                # TTAë¡œ ì˜ˆì¸¡
                avg_prob = predict_with_tta(model, image, tta_transforms, device)
                prediction = avg_prob.argmax()

                all_img_ids.append(img_id)
                all_predictions.append(prediction)

    else:
        print("ğŸ“Š ê¸°ë³¸ ì¶”ë¡  (TTA ì—†ìŒ)")

        for images, img_ids in tqdm(test_loader, desc="Inference"):
            images = images.to(device)

            # ì˜ˆì¸¡
            outputs = model(images)
            predictions = outputs.argmax(dim=1).cpu().numpy()

            all_img_ids.extend(img_ids)
            all_predictions.extend(predictions)

    return all_img_ids, all_predictions


@hydra.main(config_path="configs", config_name="config", version_base=None)
def main(cfg: DictConfig):
    """
    ë©”ì¸ ì¶”ë¡  í•¨ìˆ˜

    Args:
        cfg: Hydra config
    """
    # Hydra struct ëª¨ë“œ í•´ì œ (ìƒˆë¡œìš´ í‚¤ ì¶”ê°€ ê°€ëŠ¥í•˜ë„ë¡)
    OmegaConf.set_struct(cfg, False)

    # Config ì¶œë ¥
    print("\n" + "="*60)
    print("âš™ï¸  Inference Config")
    print("="*60)
    print(OmegaConf.to_yaml(cfg))
    print("="*60 + "\n")

    # ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
    checkpoint_path = cfg.get('checkpoint', None)

    if checkpoint_path is None:
        # ìë™ìœ¼ë¡œ ìµœì‹  ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°
        print("ğŸ“¦ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œê°€ ì§€ì •ë˜ì§€ ì•ŠìŒ â†’ ìµœì‹  ì‹¤í—˜ ìë™ ê²€ìƒ‰")
        try:
            checkpoint_path = find_latest_checkpoint(output_dir="outputs")
        except FileNotFoundError as e:
            print(str(e))
            raise
    else:
        print(f"ğŸ“¦ ì²´í¬í¬ì¸íŠ¸: {checkpoint_path}")

    # ë””ë°”ì´ìŠ¤
    if cfg.get('device', 'cuda') == 'cuda' and torch.cuda.is_available():
        device = 'cuda'
        print(f"âœ… GPU ì‚¬ìš©: {torch.cuda.get_device_name(0)}")
    else:
        device = 'cpu'
        print("âœ… CPU ì‚¬ìš©")

    # ë°ì´í„° ê²½ë¡œ
    data_dir = Path(cfg.data.data_dir)
    test_csv = data_dir / cfg.data.get('test_csv', 'sample_submission.csv')
    test_img_dir = data_dir / cfg.data.get('test_dir', 'test')

    print(f"\nğŸ“‚ ë°ì´í„° ê²½ë¡œ:")
    print(f"   CSV: {test_csv}")
    print(f"   Images: {test_img_dir}\n")

    # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ config ì½ê¸° (ìˆìœ¼ë©´)
    print("ğŸ“¦ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ ì •ë³´ í™•ì¸ ì¤‘...")
    checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)

    if 'model_config' in checkpoint:
        # ì²´í¬í¬ì¸íŠ¸ì— ëª¨ë¸ configê°€ ì €ì¥ë˜ì–´ ìˆìŒ (ìë™ ê°ì§€)
        saved_model_config = checkpoint['model_config']
        model_name = saved_model_config.get('name', 'unknown')
        print(f"âœ… ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ ì •ë³´ ë°œê²¬: {model_name}")

        # ì €ì¥ëœ configë¡œ ëª¨ë¸ ìƒì„±
        temp_cfg = OmegaConf.create({'model': saved_model_config, 'data': cfg.data})
        model = create_model_from_config(temp_cfg, num_classes=cfg.data.num_classes)
    else:
        # ëª¨ë¸ configê°€ ì—†ìŒ (êµ¬ ë²„ì „ ì²´í¬í¬ì¸íŠ¸)
        print("âš ï¸  ì²´í¬í¬ì¸íŠ¸ì— ëª¨ë¸ ì •ë³´ ì—†ìŒ â†’ config.yamlì—ì„œ ëª¨ë¸ ë¡œë“œ")
        print(f"   ì‚¬ìš© ëª¨ë¸: {cfg.model.name}")
        model = create_model_from_config(cfg, num_classes=cfg.data.num_classes)

    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    model = load_model_for_inference(model, checkpoint_path, device)

    # TTA ì‚¬ìš© ì—¬ë¶€
    use_tta = cfg.get('use_tta', True)

    if use_tta:
        # TTA ë³€í™˜ ìƒì„±
        tta_transforms = get_tta_transforms(img_size=cfg.model.get('img_size', 224))

        # TTAëŠ” DataLoader ì‚¬ìš© ì•ˆ í•¨ (ê°œë³„ ì´ë¯¸ì§€ ì²˜ë¦¬)
        # í•˜ì§€ë§Œ img_idë¥¼ ì½ê¸° ìœ„í•´ DataLoader ì‚¬ìš©
        test_transform = create_transforms_from_config(cfg, mode='test')
        test_dataset = create_test_dataset(
            csv_path=str(test_csv),
            img_dir=str(test_img_dir),
            transform=test_transform,
        )
        test_loader = create_test_dataloader(
            test_dataset,
            batch_size=1,  # TTAëŠ” 1ê°œì”© ì²˜ë¦¬
            num_workers=0,
        )

        # ì¶”ë¡ 
        img_ids, predictions = inference_with_dataloader(
            model=model,
            test_loader=test_loader,
            device=device,
            use_tta=True,
            tta_transforms=tta_transforms,
            test_img_dir=str(test_img_dir),
        )

    else:
        # ê¸°ë³¸ ì¶”ë¡  (TTA ì—†ìŒ)
        test_transform = create_transforms_from_config(cfg, mode='test')
        test_dataset = create_test_dataset(
            csv_path=str(test_csv),
            img_dir=str(test_img_dir),
            transform=test_transform,
        )
        test_loader = create_test_dataloader(
            test_dataset,
            batch_size=cfg.train.get('batch_size', 32),
            num_workers=cfg.data.get('num_workers', 4),
        )

        # ì¶”ë¡ 
        img_ids, predictions = inference_with_dataloader(
            model=model,
            test_loader=test_loader,
            device=device,
            use_tta=False,
        )

    # Submission DataFrame ìƒì„±
    submission = pd.DataFrame({
        'ID': img_ids,
        'target': predictions
    })

    # sample_submission.csvì˜ ìˆœì„œ ë§ì¶”ê¸°
    original_submission = pd.read_csv(test_csv)
    submission = original_submission[['ID']].merge(submission, on='ID', how='left')

    # ëˆ„ë½ëœ ì˜ˆì¸¡ê°’ í™•ì¸
    if submission['target'].isna().any():
        print(f"âš ï¸  ê²½ê³ : {submission['target'].isna().sum()}ê°œ ì´ë¯¸ì§€ ì˜ˆì¸¡ ì‹¤íŒ¨")

    # Submission ì €ì¥
    submission_name = cfg.get('submission_name', 'submission.csv')
    submission_path = submission_name
    submission.to_csv(submission_path, index=False)

    print(f"\nâœ… ì¶”ë¡  ì™„ë£Œ!")
    print(f"   ì „ì²´ ìƒ˜í”Œ: {len(submission)}")
    print(f"   Submission ì €ì¥: {submission_path}")
    print(f"\nğŸ“Š ì˜ˆì¸¡ ë¶„í¬:")
    print(submission['target'].value_counts().sort_index())


if __name__ == "__main__":
    main()
