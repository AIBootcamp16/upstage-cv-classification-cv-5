"""
OCR ê¸°ë°˜ ë¬¸ì„œ ë¶„ë¥˜ê¸°

OCRì—ì„œ ì¶”ì¶œí•œ íŠ¹ì§•ì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.
ë‘ ê°€ì§€ ë°©ì‹ ì§€ì›:
1. ê·œì¹™ ê¸°ë°˜ (Rule-based)
2. ML ê¸°ë°˜ (TF-IDF + Classifier)
"""

import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from collections import defaultdict
import pickle


class OCRClassifier:
    """OCR ê¸°ë°˜ ë¬¸ì„œ ë¶„ë¥˜ê¸°"""

    def __init__(self, method: str = "rule", num_classes: int = 17):
        """
        Args:
            method: "rule" (ê·œì¹™ ê¸°ë°˜) ë˜ëŠ” "ml" (ë¨¸ì‹ ëŸ¬ë‹)
            num_classes: í´ë˜ìŠ¤ ê°œìˆ˜
        """
        self.method = method
        self.num_classes = num_classes
        self.model = None
        self.vectorizer = None

        # í´ë˜ìŠ¤ë³„ ê·œì¹™ (ìˆ˜ë™ìœ¼ë¡œ ì •ì˜ - ë°ì´í„° ë¶„ì„ í›„ ì—…ë°ì´íŠ¸ í•„ìš”)
        self.class_rules = self._define_class_rules()

    def _define_class_rules(self) -> Dict:
        """
        í´ë˜ìŠ¤ë³„ ê·œì¹™ ì •ì˜ (ì˜ˆì‹œ)

        ì‹¤ì œ ì‚¬ìš©ì‹œ í´ë˜ìŠ¤ 3, 7ì˜ íŠ¹ì§•ì„ ë¶„ì„í•´ì„œ ì—…ë°ì´íŠ¸ í•„ìš”!
        """
        rules = {
            # í´ë˜ìŠ¤ 3 ê·œì¹™ ì˜ˆì‹œ (ì‹¤ì œ ë°ì´í„° ë³´ê³  ìˆ˜ì • í•„ìš”)
            3: {
                'keywords': ['íŠ¹ì •í‚¤ì›Œë“œ1', 'íŠ¹ì •í‚¤ì›Œë“œ2'],
                'min_text_length': 100,
                'has_date': True,
                'has_amount': False,
            },
            # í´ë˜ìŠ¤ 7 ê·œì¹™ ì˜ˆì‹œ (ì‹¤ì œ ë°ì´í„° ë³´ê³  ìˆ˜ì • í•„ìš”)
            7: {
                'keywords': ['ë‹¤ë¥¸í‚¤ì›Œë“œ1', 'ë‹¤ë¥¸í‚¤ì›Œë“œ2'],
                'min_text_length': 50,
                'has_phone': True,
                'has_email': False,
            },
        }
        return rules

    def predict_with_rules(self, features: Dict) -> Tuple[int, float]:
        """
        ê·œì¹™ ê¸°ë°˜ ì˜ˆì¸¡

        Args:
            features: OCRExtractor.extract_features()ì˜ ê²°ê³¼

        Returns:
            (predicted_class, confidence)
        """
        scores = defaultdict(float)

        # í´ë˜ìŠ¤ë³„ ê·œì¹™ ì²´í¬
        for class_id, rules in self.class_rules.items():
            score = 0.0
            max_score = 0.0

            # í‚¤ì›Œë“œ ì²´í¬
            if 'keywords' in rules:
                max_score += 1.0
                text = features.get('text', '').lower()
                if any(kw.lower() in text for kw in rules['keywords']):
                    score += 1.0

            # í…ìŠ¤íŠ¸ ê¸¸ì´ ì²´í¬
            if 'min_text_length' in rules:
                max_score += 0.5
                if features.get('text_length', 0) >= rules['min_text_length']:
                    score += 0.5

            # íŒ¨í„´ ì²´í¬
            for pattern_key in ['has_date', 'has_phone', 'has_email', 'has_amount']:
                if pattern_key in rules:
                    max_score += 0.5
                    if features.get(pattern_key, False) == rules[pattern_key]:
                        score += 0.5

            # ì •ê·œí™”ëœ ì ìˆ˜
            if max_score > 0:
                scores[class_id] = score / max_score

        # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ í´ë˜ìŠ¤ ì„ íƒ
        if scores:
            best_class = max(scores.items(), key=lambda x: x[1])
            return best_class[0], best_class[1]
        else:
            # ê·œì¹™ì— ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ -1 ë°˜í™˜ (ë‹¤ë¥¸ ëª¨ë¸ ì‚¬ìš©)
            return -1, 0.0

    def train_ml_model(self, train_data: pd.DataFrame, train_labels: np.ndarray):
        """
        ML ëª¨ë¸ í•™ìŠµ (TF-IDF + Logistic Regression)

        Args:
            train_data: OCR ì¶”ì¶œ ê²°ê³¼ DataFrame
            train_labels: ë ˆì´ë¸” (0~16)
        """
        from sklearn.feature_extraction.text import TfidfVectorizer
        from sklearn.linear_model import LogisticRegression
        from sklearn.preprocessing import StandardScaler
        from sklearn.pipeline import Pipeline

        print("ğŸ“š ML ëª¨ë¸ í•™ìŠµ ì¤‘...")

        # í…ìŠ¤íŠ¸ íŠ¹ì§•
        texts = train_data['text'].fillna('')

        # TF-IDF ë²¡í„°í™”
        self.vectorizer = TfidfVectorizer(
            max_features=1000,
            ngram_range=(1, 2),
            min_df=2
        )

        # íŒŒì´í”„ë¼ì¸ ìƒì„±
        self.model = Pipeline([
            ('scaler', StandardScaler(with_mean=False)),
            ('classifier', LogisticRegression(
                max_iter=1000,
                multi_class='multinomial',
                random_state=42
            ))
        ])

        # í•™ìŠµ
        X = self.vectorizer.fit_transform(texts)
        self.model.fit(X, train_labels)

        print("âœ… ML ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")

    def predict_with_ml(self, features: Dict) -> Tuple[int, float]:
        """
        ML ëª¨ë¸ë¡œ ì˜ˆì¸¡

        Args:
            features: OCRExtractor.extract_features()ì˜ ê²°ê³¼

        Returns:
            (predicted_class, confidence)
        """
        if self.model is None or self.vectorizer is None:
            raise ValueError("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. train_ml_model()ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")

        text = features.get('text', '')

        # TF-IDF ë³€í™˜
        X = self.vectorizer.transform([text])

        # ì˜ˆì¸¡
        pred_class = self.model.predict(X)[0]
        pred_proba = self.model.predict_proba(X)[0]
        confidence = pred_proba[pred_class]

        return int(pred_class), float(confidence)

    def predict(self, features: Dict) -> Tuple[int, float]:
        """
        ì˜ˆì¸¡ (methodì— ë”°ë¼ ìë™ ì„ íƒ)

        Args:
            features: OCRExtractor.extract_features()ì˜ ê²°ê³¼

        Returns:
            (predicted_class, confidence)
        """
        if self.method == "rule":
            return self.predict_with_rules(features)
        elif self.method == "ml":
            return self.predict_with_ml(features)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” method: {self.method}")

    def predict_batch(self, features_list: List[Dict]) -> Tuple[np.ndarray, np.ndarray]:
        """
        ë°°ì¹˜ ì˜ˆì¸¡

        Args:
            features_list: íŠ¹ì§• ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸

        Returns:
            (predictions, confidences)
        """
        predictions = []
        confidences = []

        for features in features_list:
            pred, conf = self.predict(features)
            predictions.append(pred)
            confidences.append(conf)

        return np.array(predictions), np.array(confidences)

    def save(self, path: str):
        """ëª¨ë¸ ì €ì¥"""
        model_data = {
            'method': self.method,
            'num_classes': self.num_classes,
            'model': self.model,
            'vectorizer': self.vectorizer,
            'class_rules': self.class_rules
        }

        with open(path, 'wb') as f:
            pickle.dump(model_data, f)

        print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {path}")

    @classmethod
    def load(cls, path: str):
        """ëª¨ë¸ ë¡œë“œ"""
        with open(path, 'rb') as f:
            model_data = pickle.load(f)

        classifier = cls(
            method=model_data['method'],
            num_classes=model_data['num_classes']
        )
        classifier.model = model_data['model']
        classifier.vectorizer = model_data['vectorizer']
        classifier.class_rules = model_data['class_rules']

        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {path}")
        return classifier


def create_ocr_predictions_csv(
    test_dir: str,
    output_path: str,
    extractor,
    classifier,
    sample_submission_path: str = "datasets_fin/sample_submission.csv"
):
    """
    OCR ê¸°ë°˜ ì˜ˆì¸¡ CSV ìƒì„±

    Args:
        test_dir: í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
        output_path: ì¶œë ¥ CSV ê²½ë¡œ
        extractor: OCRExtractor ì¸ìŠ¤í„´ìŠ¤
        classifier: OCRClassifier ì¸ìŠ¤í„´ìŠ¤
        sample_submission_path: ìƒ˜í”Œ submission ê²½ë¡œ
    """
    from tqdm import tqdm

    # ìƒ˜í”Œ submission ë¡œë“œ
    sample_df = pd.read_csv(sample_submission_path)

    # ê²°ê³¼ ì €ì¥ìš©
    predictions = []
    confidences = []

    print(f"ğŸ” OCR ì˜ˆì¸¡ ì‹œì‘ (ì´ {len(sample_df)}ê°œ ì´ë¯¸ì§€)")

    for idx, row in tqdm(sample_df.iterrows(), total=len(sample_df)):
        image_name = row['ID']
        image_path = Path(test_dir) / image_name

        if not image_path.exists():
            print(f"âš ï¸ ì´ë¯¸ì§€ ì—†ìŒ: {image_name}")
            predictions.append(0)
            confidences.append(0.0)
            continue

        # OCR ì¶”ì¶œ
        ocr_result = extractor.extract_text(str(image_path))

        # íŠ¹ì§• ì¶”ì¶œ
        features = extractor.extract_features(ocr_result)
        features['text'] = ocr_result['text']

        # ì˜ˆì¸¡
        pred, conf = classifier.predict(features)

        predictions.append(pred)
        confidences.append(conf)

    # DataFrame ìƒì„±
    result_df = pd.DataFrame({
        'ID': sample_df['ID'],
        'target': predictions,
        'confidence': confidences
    })

    # ì €ì¥
    result_df.to_csv(output_path, index=False)
    print(f"âœ… OCR ì˜ˆì¸¡ ì €ì¥ ì™„ë£Œ: {output_path}")

    # í†µê³„ ì¶œë ¥
    print(f"\nğŸ“Š ì˜ˆì¸¡ í†µê³„:")
    print(f"  í‰ê·  confidence: {np.mean(confidences):.3f}")
    print(f"  ì˜ˆì¸¡ ë¶ˆê°€ (-1): {sum(np.array(predictions) == -1)}ê°œ")
    print(f"\ní´ë˜ìŠ¤ë³„ ë¶„í¬:")
    print(result_df['target'].value_counts().sort_index())

    return result_df


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("OCR Classifier í…ŒìŠ¤íŠ¸")

    # ê·œì¹™ ê¸°ë°˜ ë¶„ë¥˜ê¸°
    classifier = OCRClassifier(method="rule")

    # í…ŒìŠ¤íŠ¸ íŠ¹ì§•
    test_features = {
        'text': 'Invoice 2024-01-01 Total: $100',
        'text_length': 30,
        'has_date': True,
        'has_amount': True,
        'has_invoice_keywords': True
    }

    pred, conf = classifier.predict(test_features)
    print(f"ì˜ˆì¸¡: í´ë˜ìŠ¤ {pred}, ì‹ ë¢°ë„ {conf:.3f}")
