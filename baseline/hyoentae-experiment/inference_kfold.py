"""
K-Fold ì•™ìƒë¸” ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸

ì—¬ëŸ¬ foldì˜ ëª¨ë¸ì„ ì•™ìƒë¸”í•˜ì—¬ ìµœì¢… ì˜ˆì¸¡ì„ ìƒì„±í•©ë‹ˆë‹¤.
ê° foldì˜ ì˜ˆì¸¡ í™•ë¥ ì„ í‰ê· ë‚´ì–´ ìµœì¢… í´ë˜ìŠ¤ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    # ê¸°ë³¸ ì‚¬ìš© (ìë™ìœ¼ë¡œ ìµœì‹  K-Fold ì‹¤í—˜ ì°¾ê¸°, ëª¨ë“  fold ì‚¬ìš©)
    python inference_kfold.py

    # íŠ¹ì • K-Fold ì‹¤í—˜ ë””ë ‰í† ë¦¬ ì§€ì •
    python inference_kfold.py kfold_dir=outputs/2025-11-05/03-32-32

    # TTA ì‚¬ìš© (ë” ëŠë¦¬ì§€ë§Œ ì„±ëŠ¥ í–¥ìƒ)
    python inference_kfold.py use_tta=true

    # Val F1 ê¸°ì¤€ ìƒìœ„ 3ê°œ foldë§Œ ì‚¬ìš©
    python inference_kfold.py top_k_folds=3

    # íŠ¹ì • fold ë²ˆí˜¸ë“¤ë§Œ ì‚¬ìš© (ì˜ˆ: fold 0, 2, 4)
    python inference_kfold.py 'use_folds=[0,2,4]'

    # ì¡°í•© ì˜ˆì œ
    python inference_kfold.py top_k_folds=3 use_tta=true

ì¥ì :
    - ë‹¨ì¼ ëª¨ë¸ë³´ë‹¤ ì•ˆì •ì ì´ê³  ë†’ì€ ì„±ëŠ¥
    - ê° foldê°€ ë‹¤ë¥¸ validation setìœ¼ë¡œ í•™ìŠµë˜ì–´ ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ
    - íŠ¹ì • foldë§Œ ì„ íƒí•˜ì—¬ ì¶”ë¡  ì†ë„ì™€ ì„±ëŠ¥ ì¡°ì ˆ ê°€ëŠ¥
"""

import hydra
from omegaconf import DictConfig, OmegaConf
import torch
import pandas as pd
import numpy as np
from pathlib import Path
from tqdm import tqdm
import json
import cv2

from src.models.classifier import DocumentClassifier
from src.data.dataset import create_test_dataset, create_test_dataloader
from src.data.transforms import create_transforms_from_config, get_tta_transforms


def subclass_to_class(subclass_pred):
    """
    Sub-class ì˜ˆì¸¡ì„ ì›ë˜ classë¡œ ë³€í™˜ (38-class â†’ 17-class)

    Args:
        subclass_pred: Sub-class ì˜ˆì¸¡ (0~37)

    Returns:
        ì›ë˜ class (0~16)
    """
    # Sub-class ë²”ìœ„ ì²´í¬
    if 30 <= subclass_pred <= 39:
        return 3
    elif 70 <= subclass_pred <= 79:
        return 7
    elif 140 <= subclass_pred <= 143:
        return 14
    else:
        # ë‚˜ë¨¸ì§€ëŠ” ê·¸ëŒ€ë¡œ
        return subclass_pred


def find_latest_kfold_dir(output_dir: str = "outputs") -> Path:
    """
    ê°€ì¥ ìµœì‹  K-Fold ì‹¤í—˜ ë””ë ‰í† ë¦¬ ì°¾ê¸°

    Args:
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: "outputs")

    Returns:
        K-Fold ì‹¤í—˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ
    """
    output_path = Path(output_dir)

    if not output_path.exists():
        raise FileNotFoundError(f"ì¶œë ¥ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {output_dir}")

    # ëª¨ë“  ë‚ ì§œ ë””ë ‰í† ë¦¬ ì°¾ê¸°
    date_dirs = sorted([d for d in output_path.iterdir() if d.is_dir()])

    if not date_dirs:
        raise FileNotFoundError(f"ì‹¤í—˜ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {output_dir}")

    # ìµœì‹  ë‚ ì§œ ë””ë ‰í† ë¦¬ ì„ íƒ
    latest_date_dir = date_dirs[-1]

    # ì‹œê°„ ë””ë ‰í† ë¦¬ë“¤ ì°¾ê¸°
    time_dirs = sorted([d for d in latest_date_dir.iterdir() if d.is_dir()])

    # ê° ì‹œê°„ ë””ë ‰í† ë¦¬ì—ì„œ K-Fold ì‹¤í—˜ ì°¾ê¸° (kfold_summary.json ì¡´ì¬ ì—¬ë¶€)
    for time_dir in reversed(time_dirs):  # ìµœì‹ ë¶€í„° ê²€ìƒ‰
        if (time_dir / "kfold_summary.json").exists():
            print(f"âœ… K-Fold ì‹¤í—˜ ë°œê²¬: {time_dir}")
            return time_dir

    raise FileNotFoundError(f"K-Fold ì‹¤í—˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. kfold_summary.jsonì´ ì—†ìŠµë‹ˆë‹¤.")


def load_kfold_models(kfold_dir: Path, device: str, top_k_folds: int = None, use_folds: list = None) -> list:
    """
    K-Fold ë””ë ‰í† ë¦¬ì—ì„œ fold ëª¨ë¸ ë¡œë“œ (ì„ íƒì ìœ¼ë¡œ íŠ¹ì • foldë§Œ)

    Args:
        kfold_dir: K-Fold ì‹¤í—˜ ë””ë ‰í† ë¦¬
        device: ë””ë°”ì´ìŠ¤ ('cuda' ë˜ëŠ” 'cpu')
        top_k_folds: validation f1 ê¸°ì¤€ ìƒìœ„ kê°œ foldë§Œ ì„ íƒ (Noneì´ë©´ ëª¨ë‘ ì‚¬ìš©)
        use_folds: íŠ¹ì • fold ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ëª¨ë‘ ì‚¬ìš©)

    Returns:
        [(model, fold_idx, val_f1, num_classes), ...] ë¦¬ìŠ¤íŠ¸
    """
    # K-Fold summary ì½ê¸°
    summary_path = kfold_dir / "kfold_summary.json"
    with open(summary_path, 'r') as f:
        summary = json.load(f)

    print(f"\nğŸ“Š K-Fold Summary:")
    print(f"   Total Folds: {summary['n_folds']}")
    print(f"   Average Val F1: {summary['average']['val_macro_f1']:.4f}")
    print(f"   Average Train F1: {summary['average']['train_macro_f1']:.4f}\n")

    # Fold ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
    fold_results = summary['fold_results']

    # Fold ì„ íƒ ë¡œì§
    if use_folds is not None:
        # íŠ¹ì • fold ë²ˆí˜¸ë“¤ë§Œ ì‚¬ìš©
        fold_results = [f for f in fold_results if f['fold'] in use_folds]
        print(f"ğŸ¯ íŠ¹ì • Fold ì„ íƒ: {use_folds}")
        print(f"   ì„ íƒëœ Fold ê°œìˆ˜: {len(fold_results)}\n")
    elif top_k_folds is not None:
        # Val F1 ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ kê°œë§Œ ì„ íƒ
        fold_results = sorted(fold_results, key=lambda x: x['val_f1'], reverse=True)[:top_k_folds]
        selected_folds = [f['fold'] for f in fold_results]
        print(f"ğŸ† ìƒìœ„ {top_k_folds}ê°œ Fold ì„ íƒ (Val F1 ê¸°ì¤€)")
        print(f"   ì„ íƒëœ Fold: {selected_folds}")
        print(f"   Val F1 ë²”ìœ„: {fold_results[-1]['val_f1']:.4f} ~ {fold_results[0]['val_f1']:.4f}\n")
    else:
        print(f"ğŸ“¦ ì „ì²´ {len(fold_results)}ê°œ Fold ì‚¬ìš©\n")

    # ê° fold ëª¨ë¸ ë¡œë“œ
    models = []

    for fold_info in fold_results:
        fold_idx = fold_info['fold']
        val_f1 = fold_info['val_f1']

        fold_dir = kfold_dir / f"fold_{fold_idx}"
        checkpoint_path = fold_dir / "best.pth"

        if not checkpoint_path.exists():
            print(f"âš ï¸  Fold {fold_idx} ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ, ê±´ë„ˆëœ€: {checkpoint_path}")
            continue

        print(f"ğŸ“¦ Fold {fold_idx} ë¡œë”©... (Val F1: {val_f1:.4f})")

        # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
        checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)

        # Config ë³µì› (model_config í‚¤ë¡œ ì €ì¥ë˜ì–´ ìˆìŒ)
        if 'model_config' in checkpoint:
            model_cfg = checkpoint['model_config']
        elif 'config' in checkpoint:
            model_cfg = checkpoint['config']['model']
        else:
            raise ValueError(f"ì²´í¬í¬ì¸íŠ¸ì— model_config ë˜ëŠ” configê°€ ì—†ìŠµë‹ˆë‹¤: {checkpoint_path}")

        # num_classes í™•ì¸: ì‹¤ì œ ê°€ì¤‘ì¹˜ shapeë¡œë¶€í„° ì¶”ë¡  (configê°€ ì˜ëª»ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŒ)
        fc_weight_key = None
        for key in checkpoint['model_state_dict'].keys():
            if 'fc.weight' in key or 'classifier.weight' in key or 'head.weight' in key:
                fc_weight_key = key
                break

        if fc_weight_key:
            actual_num_classes = checkpoint['model_state_dict'][fc_weight_key].shape[0]
            config_num_classes = model_cfg.get('num_classes', 17)

            if actual_num_classes != config_num_classes:
                print(f"   âš ï¸  Config num_classes={config_num_classes}, ì‹¤ì œ ê°€ì¤‘ì¹˜={actual_num_classes} â†’ ì‹¤ì œ ê°€ì¤‘ì¹˜ ì‚¬ìš©")
                num_classes = actual_num_classes
            else:
                num_classes = config_num_classes
        else:
            num_classes = model_cfg.get('num_classes', 17)

        # ëª¨ë¸ ìƒì„±
        model = DocumentClassifier(
            model_name=model_cfg['architecture'],
            num_classes=num_classes,
            pretrained=False,
            dropout=model_cfg.get('dropout', 0.3)
        )

        # ê°€ì¤‘ì¹˜ ë¡œë“œ
        model.load_state_dict(checkpoint['model_state_dict'])
        model = model.to(device)
        model.eval()

        models.append((model, fold_idx, val_f1, num_classes))

        print(f"   âœ… Fold {fold_idx} ë¡œë“œ ì™„ë£Œ (num_classes={num_classes})")

    if not models:
        raise ValueError(f"ë¡œë“œëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. fold_*/best.pth íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

    print(f"\nâœ… ì´ {len(models)}ê°œ fold ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n")

    return models


@torch.no_grad()
def predict_with_ensemble(
    models: list,
    test_loader,
    device: str,
    use_tta: bool = False,
    tta_transforms: list = None,
    test_img_dir: Path = None,
) -> tuple:
    """
    K-Fold ì•™ìƒë¸” ì˜ˆì¸¡ (Sub-class ìë™ ë³€í™˜ ì§€ì›)

    Args:
        models: [(model, fold_idx, val_f1, num_classes), ...] ë¦¬ìŠ¤íŠ¸
        test_loader: Test DataLoader
        device: ë””ë°”ì´ìŠ¤
        use_tta: TTA ì‚¬ìš© ì—¬ë¶€
        tta_transforms: TTA ë³€í™˜ ë¦¬ìŠ¤íŠ¸
        test_img_dir: Test ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬

    Returns:
        (img_ids, predictions) íŠœí”Œ
    """
    all_img_ids = []
    all_predictions = []

    # Sub-class ëª¨ë¸ í™•ì¸ (ì²« ë²ˆì§¸ ëª¨ë¸ì˜ num_classesë¡œ íŒë‹¨)
    num_classes = models[0][3]
    is_subclass_model = (num_classes == 38)

    if is_subclass_model:
        print(f"ğŸ·ï¸  Sub-class ëª¨ë¸ ê°ì§€ (38-class â†’ 17-class ìë™ ë³€í™˜)")

    if use_tta:
        print("ğŸ”„ K-Fold ì•™ìƒë¸” + TTA ì¶”ë¡  (ê°€ì¥ ê°•ë ¥!)")
        print(f"   ëª¨ë¸ ìˆ˜: {len(models)}")
        print(f"   TTA ë²„ì „ ìˆ˜: {len(tta_transforms)}")
        print(f"   ì´ ì˜ˆì¸¡ íšŸìˆ˜: {len(models)} Ã— {len(tta_transforms)} = {len(models) * len(tta_transforms)}")

        # TTAëŠ” ê°œë³„ ì´ë¯¸ì§€ ì²˜ë¦¬
        for images, img_ids in tqdm(test_loader, desc="K-Fold Ensemble + TTA"):
            for i, img_id in enumerate(img_ids):
                # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
                if img_id.endswith('.jpg') or img_id.endswith('.png'):
                    img_path = test_img_dir / img_id
                else:
                    img_path_jpg = test_img_dir / f"{img_id}.jpg"
                    img_path_png = test_img_dir / f"{img_id}.png"
                    img_path = img_path_jpg if img_path_jpg.exists() else img_path_png

                if not img_path.exists():
                    print(f"âš ï¸  ì´ë¯¸ì§€ ì—†ìŒ: {img_path}")
                    continue

                # ì´ë¯¸ì§€ ì½ê¸°
                image = cv2.imread(str(img_path))
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

                # ëª¨ë“  fold + TTA ì˜ˆì¸¡ ìˆ˜ì§‘
                ensemble_probs = []

                for model, fold_idx, val_f1, _ in models:
                    for transform in tta_transforms:
                        # Augmentation ì ìš©
                        augmented = transform(image=image)
                        img_tensor = augmented['image'].unsqueeze(0).to(device)

                        # ì˜ˆì¸¡
                        output = model(img_tensor)
                        prob = torch.softmax(output, dim=1).cpu().numpy()[0]
                        ensemble_probs.append(prob)

                # í‰ê·  í™•ë¥ 
                avg_prob = np.mean(ensemble_probs, axis=0)
                prediction = avg_prob.argmax()

                # Sub-class â†’ class ë³€í™˜
                if is_subclass_model:
                    prediction = subclass_to_class(prediction)

                all_img_ids.append(img_id)
                all_predictions.append(prediction)

    else:
        print("ğŸ“Š K-Fold ì•™ìƒë¸” ì¶”ë¡  (TTA ì—†ìŒ)")
        print(f"   ëª¨ë¸ ìˆ˜: {len(models)}")

        for images, img_ids in tqdm(test_loader, desc="K-Fold Ensemble"):
            images = images.to(device)

            # ëª¨ë“  fold ëª¨ë¸ì˜ ì˜ˆì¸¡ ìˆ˜ì§‘
            batch_ensemble_probs = []

            for model, fold_idx, val_f1, _ in models:
                outputs = model(images)
                probs = torch.softmax(outputs, dim=1).cpu().numpy()  # [batch_size, num_classes]
                batch_ensemble_probs.append(probs)

            # í‰ê·  í™•ë¥  (ëª¨ë“  fold)
            avg_probs = np.mean(batch_ensemble_probs, axis=0)  # [batch_size, num_classes]
            predictions = avg_probs.argmax(axis=1)

            # Sub-class â†’ class ë³€í™˜
            if is_subclass_model:
                predictions = [subclass_to_class(p) for p in predictions]

            all_img_ids.extend(img_ids)
            all_predictions.extend(predictions)

    return all_img_ids, all_predictions


@hydra.main(config_path="configs", config_name="config", version_base=None)
def main(cfg: DictConfig):
    """
    ë©”ì¸ K-Fold ì•™ìƒë¸” ì¶”ë¡  í•¨ìˆ˜
    """
    print("\n" + "="*60)
    print("ğŸ”€ K-Fold ì•™ìƒë¸” ì¶”ë¡ ")
    print("="*60)

    # Hydra struct ëª¨ë“œ í•´ì œ (ìƒˆë¡œìš´ í‚¤ ì¶”ê°€ ê°€ëŠ¥í•˜ë„ë¡)
    OmegaConf.set_struct(cfg, False)

    # K-Fold ë””ë ‰í† ë¦¬
    kfold_dir = cfg.get('kfold_dir', None)

    if kfold_dir is None:
        print("ğŸ“‚ K-Fold ë””ë ‰í† ë¦¬ê°€ ì§€ì •ë˜ì§€ ì•ŠìŒ â†’ ìµœì‹  ì‹¤í—˜ ìë™ ê²€ìƒ‰")
        try:
            kfold_dir = find_latest_kfold_dir(output_dir="outputs")
        except FileNotFoundError as e:
            print(str(e))
            raise
    else:
        kfold_dir = Path(kfold_dir)
        print(f"ğŸ“‚ K-Fold ë””ë ‰í† ë¦¬: {kfold_dir}")

    # ë””ë°”ì´ìŠ¤
    if cfg.get('device', 'cuda') == 'cuda' and torch.cuda.is_available():
        device = 'cuda'
        print(f"âœ… GPU ì‚¬ìš©: {torch.cuda.get_device_name(0)}")
    else:
        device = 'cpu'
        print("âœ… CPU ì‚¬ìš©")

    # Fold ì„ íƒ ì˜µì…˜
    top_k_folds = cfg.get('top_k_folds', None)
    use_folds = cfg.get('use_folds', None)

    # K-Fold ëª¨ë¸ë“¤ ë¡œë“œ
    models = load_kfold_models(kfold_dir, device, top_k_folds=top_k_folds, use_folds=use_folds)

    # ë°ì´í„° ê²½ë¡œ
    data_dir = Path(cfg.data.data_dir)
    test_csv = data_dir / cfg.data.get('test_csv', 'sample_submission.csv')
    test_img_dir = data_dir / cfg.data.get('test_dir', 'test')

    print(f"ğŸ“‚ ë°ì´í„° ê²½ë¡œ:")
    print(f"   Test CSV: {test_csv}")
    print(f"   Test Images: {test_img_dir}\n")

    # TTA ì‚¬ìš© ì—¬ë¶€
    use_tta = cfg.get('use_tta', False)

    # ëª¨ë¸ configì—ì„œ ì´ë¯¸ì§€ í¬ê¸° ê°€ì ¸ì˜¤ê¸° (ì²« ë²ˆì§¸ ëª¨ë¸)
    checkpoint = torch.load(kfold_dir / f"fold_{models[0][1]}" / "best.pth", map_location='cpu', weights_only=False)

    # Config ë³µì› (model_config í‚¤ë¡œ ì €ì¥ë˜ì–´ ìˆìŒ)
    if 'model_config' in checkpoint:
        img_size = checkpoint['model_config']['input_size']
    elif 'config' in checkpoint:
        img_size = checkpoint['config']['model']['input_size']
    else:
        raise ValueError(f"ì²´í¬í¬ì¸íŠ¸ì— model_config ë˜ëŠ” configê°€ ì—†ìŠµë‹ˆë‹¤")

    if use_tta:
        # TTA ë³€í™˜ ìƒì„±
        tta_transforms = get_tta_transforms(img_size=img_size)
        print(f"âœ… TTA ë³€í™˜ ìƒì„± ì™„ë£Œ (ë²„ì „ ìˆ˜: {len(tta_transforms)})")
    else:
        tta_transforms = None

    # Test transform ìƒì„±
    test_transform = create_transforms_from_config(cfg, mode='test')

    # Configì—ì„œ img_size ì„¤ì • (ëª¨ë¸ê³¼ ì¼ì¹˜í•˜ë„ë¡)
    OmegaConf.set_struct(cfg, False)
    if 'model' not in cfg:
        cfg.model = {}
    cfg.model.img_size = img_size
    OmegaConf.set_struct(cfg, True)

    # Test dataset ìƒì„±
    test_dataset = create_test_dataset(
        csv_path=str(test_csv),
        img_dir=str(test_img_dir),
        transform=test_transform
    )

    # Test dataloader ìƒì„±
    batch_size = 1 if use_tta else cfg.train.get('batch_size', 32)
    test_loader = create_test_dataloader(
        test_dataset,
        batch_size=batch_size,
        num_workers=cfg.data.get('num_workers', 4)
    )

    print(f"ğŸ“¦ Test Dataset: {len(test_dataset)}ê°œ ì´ë¯¸ì§€")
    print(f"   Batch Size: {batch_size}\n")

    # K-Fold ì•™ìƒë¸” ì¶”ë¡ 
    print("ğŸš€ ì¶”ë¡  ì‹œì‘...\n")

    img_ids, predictions = predict_with_ensemble(
        models=models,
        test_loader=test_loader,
        device=device,
        use_tta=use_tta,
        tta_transforms=tta_transforms,
        test_img_dir=test_img_dir
    )

    # Submission ìƒì„±
    submission_df = pd.DataFrame({
        'ID': img_ids,
        'target': predictions
    })

    # ì €ì¥ ê²½ë¡œ
    submission_name = cfg.get('submission_name', 'submission_kfold.csv')
    if use_tta:
        submission_name = submission_name.replace('.csv', '_tta.csv')

    submission_path = kfold_dir / submission_name

    submission_df.to_csv(submission_path, index=False)

    print(f"\nâœ… ì¶”ë¡  ì™„ë£Œ!")
    print(f"   ì˜ˆì¸¡ ê°œìˆ˜: {len(predictions)}")
    print(f"   Submission ì €ì¥: {submission_path}")

    # í´ë˜ìŠ¤ ë¶„í¬ ì¶œë ¥
    print(f"\nğŸ“Š ì˜ˆì¸¡ í´ë˜ìŠ¤ ë¶„í¬:")
    for cls in range(17):
        count = (submission_df['target'] == cls).sum()
        print(f"   Class {cls}: {count}ê°œ ({count/len(predictions)*100:.1f}%)")


if __name__ == "__main__":
    main()
